# Pashto Text Preprocessing Toolkit (TPTLP)

A Python toolkit for **text preprocessing in Pashto**, a low-resource and morphologically rich language.  
Includes normalization, tokenization, stopword removal, stemming, lemmatization, POS tagging, and TF-IDF support.

---

## üöÄ Features

- ‚úÖ Unicode normalization for Pashto
- ‚úÖ Whitespace-based tokenization
- ‚úÖ Customizable stopword removal
- ‚úÖ Dictionary + affix-based stemming
- ‚úÖ Lemmatization using rule-based mapping
- ‚úÖ Rule-based POS tagging (Pashto lexicon)
- ‚úÖ TF-IDF keyword extraction
- ‚úÖ Supports raw corpus and single text inputs

---

## üì¶ Installation

```bash
git clone https://github.com/AryanQadir/Pashto_Text_Preprocessing
cd Pashto_Text_Preprocessing
pip install .
```

---

## üß™ Example Usage (from `examples/full_pipeline_with_pos.py`)

```python
from pashto_nlp.normalization import normalize_text
from pashto_nlp.tokenization import tokenize
from pashto_nlp.stopwords import load_stopwords, remove_stopwords
from pashto_nlp.stemming import stem_tokens
from pashto_nlp.lemmatization import lemmatize_tokens
from pashto_nlp.pos_tagger import rule_based_pos_tag


text = "ÿ≤Ÿá ⁄öŸàŸàŸÜ⁄ÅŸä ÿ™Ÿá ⁄ÅŸÖ ÿßŸà ⁄©ÿ™ÿßÿ®ŸàŸÜŸá ŸÑŸàŸÑŸÖ"
normalized = normalize_text(text)
tokens = tokenize(normalized)
stopwords = load_stopwords("resources/stopwords.txt")
filtered = remove_stopwords(tokens, stopwords)
stemmed = stem_tokens(filtered)
lemmatized = lemmatize_tokens(filtered)
tags = rule_based_pos_tag(filtered)

print("Stemmed:", stemmed)
print("Lemmatized:", lemmatized) 
print("POS Tags:", tags)
```

---

## üìÇ Folder Structure

```
Pashto_Text_Preprocessing/
‚îú‚îÄ‚îÄ pashto_nlp/                # Processing modules
‚îú‚îÄ‚îÄ datasets/                  # Raw and cleaned text corpus
‚îú‚îÄ‚îÄ resources/                 # Stopwords, suffixes, prefixes
‚îú‚îÄ‚îÄ results/                   # Output files
‚îú‚îÄ‚îÄ tfidf/                     # TF-IDF features
‚îú‚îÄ‚îÄ examples/                  # Scripts (e.g., run_processing.py)
‚îú‚îÄ‚îÄ figures/                   # Optional visual outputs
‚îú‚îÄ‚îÄ paper.md                   # JOSS paper
‚îú‚îÄ‚îÄ README.md                  # This file
‚îî‚îÄ‚îÄ setup.py                   # Pip installer
```

---

## üìñ Dataset

The pipeline has been evaluated on the **Pashto Text Corpus (PTC)** containing over **50,000 documents** from books, news, and historical texts.

## Full Dataset (50,000 Pashto Documents)
Due to size limitations, the full dataset is not included in this repository.
If you would like access to the full Pashto corpus used in this research, please contact on my email aryanqadira1@gmail.com.
The sample data in `datasets/raw_corpus` can be used to test and explore the preprocessing pipeline.
---

## üìú License

MIT License. See [`LICENSE`](LICENSE).

---

## üë®‚Äçüíª Authors

- **Abdul Qadir** ‚Äì University of Balochistan  
  ORCID: https://orcid.org/0009-0004-0413-488X
- **Ihsan Ullah**

---

## üìñ Citation

If you use this toolkit in your research, please cite the following paper:

> Abdul Qadir (2024). *Pashto Text Preprocessing for Low-Resource Language: Pashto Language*. Journal of Open Source Software.

```bibtex
@article{qadir2024pashto,
  title={Pashto Text Preprocessing for Low-Resource Language: Pashto Language},
  author={Qadir, Abdul},
  journal={Journal of Open Source Software},
  year={2024},
  publisher={The Open Journals}
}
```

---

## üôè Acknowledgments

Developed as part of an MS research project in Pashto NLP. Supported by open-source software and community efforts to process low-resource languages.
